{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:52.419107283Z",
     "start_time": "2023-11-15T16:32:51.998468414Z"
    }
   },
   "id": "74489d313ee2c792"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:52.423061786Z",
     "start_time": "2023-11-15T16:32:52.047652208Z"
    }
   },
   "id": "9a8e52de1661e97f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:52.423325545Z",
     "start_time": "2023-11-15T16:32:52.047811497Z"
    }
   },
   "id": "5a0772d890163619"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39512221537109155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:52] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# В этом коде происходит следующее:\n",
    "# \n",
    "# Загружаются данные диабета с помощью load_diabetes() из sklearn.datasets.\n",
    "# X - признаки (data), y - целевая переменная (target)\n",
    "# Создается модель регрессии XGBRegressor с линейной регрессией как целевой функцией и заданным random_state.\n",
    "# Обучаем модель на данных X и y.\n",
    "# Делаем предсказание на тех же данных X.\n",
    "# Вычисляем среднеквадратичную ошибку между предсказанными значениями и истинными y.\n",
    "# Выводим корень из среднеквадратичной ошибки - то есть RMSE (root mean squared error).\n",
    "# Таким образом, в коде обучается модель регрессии XGB на данных о диабете, делаются предсказания и оценивается их качество с помощью RMSE.\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(X)\n",
    "\n",
    "mse=mean_squared_error(y, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:52.431556410Z",
     "start_time": "2023-11-15T16:32:52.047903747Z"
    }
   },
   "id": "b674b753e3d00b2e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, objective='reg:linear', ...)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, objective=&#x27;reg:linear&#x27;, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переменная xgb_model содержит обученную модель регрессии XGBRegressor.\n",
    "xgb_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:52.432292310Z",
     "start_time": "2023-11-15T16:32:52.335434164Z"
    }
   },
   "id": "9b5b8e38e5daeee3"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[212   0]\n",
      " [  0 357]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# В этом коде происходит следующее:\n",
    "# \n",
    "# Загружаются данные о раке молочной железы с помощью load_breast_cancer() из sklearn.datasets.\n",
    "# X - признаки, y - целевая переменная (0 или 1)\n",
    "# Создается модель классификации XGBClassifier с логистической регрессией как целевой функцией и фиксированным random_state.\n",
    "# Обучаем модель на данных X и y.\n",
    "# Делаем предсказание на тех же данных X.\n",
    "# Выводим матрицу ошибок (confusion matrix) по истинным значениям y и предсказанным y_pred.\n",
    "# Матрица ошибок показывает, как часто модель:\n",
    "# \n",
    "# Правильно предсказывала класс 0 (истинно отрицательные)\n",
    "# Неправильно предсказывала класс 0 как 1 (ложно положительные)\n",
    "# Правильно предсказывала класс 1 (истинно положительные)\n",
    "# Неправильно предсказывала класс 1 как 0 (ложно отрицательные)\n",
    "# Таким образом, мы обучили модель классификации и оценили качество её предсказаний с помощью матрицы ошибок.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(X)\n",
    "\n",
    "print(confusion_matrix(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:53.392680799Z",
     "start_time": "2023-11-15T16:32:52.341516059Z"
    }
   },
   "id": "2bdfb7944a201e04"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  0  0]\n",
      " [ 0 71  0]\n",
      " [ 0  0 48]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# В этом примере происходит следующее:\n",
    "# \n",
    "# Загружаются данные о винах (wine dataset) с помощью load_wine() из sklearn.datasets.\n",
    "# X - признаки (характеристики вин), y - метки классов (сорта вин)\n",
    "# Создается модель классификации XGBClassifier, где целевая функция \"multi:softprob\" для мультиклассовой классификации (3 класса вина).\n",
    "# Модель обучается на данных X и y.\n",
    "# Делаем предсказания на тех же данных.\n",
    "# Выводим матрицу ошибок между предсказанными метками y_pred и истинными y.\n",
    "# Матрица ошибок покажет, как часто модель:\n",
    "# \n",
    "# Правильно предсказывала каждый класс\n",
    "# Неправильно классифицировала объекты одного класса как другой\n",
    "# Таким образом, мы обучили модель для мультиклассовой классификации вин и оценили качество с помощью матрицы ошибок.\n",
    "wine = load_wine()\n",
    "\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(X)\n",
    "\n",
    "print(confusion_matrix(y, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:53.904960892Z",
     "start_time": "2023-11-15T16:32:53.389001791Z"
    }
   },
   "id": "d2692e31a0d432b4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:53] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [57.8878367  58.38510758 68.69963127 65.94107893 64.05194017]\n",
      "Mean: 62.993\n",
      "Std: 4.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# В этом коде происходит:\n",
    "# \n",
    "# Загрузка данных о диабете.\n",
    "# Разбиение данных на обучающую и тестовую выборки с помощью кросс-валидации KFold.\n",
    "# Обучение модели XGBRegressor на каждой обучающей выборке.\n",
    "# Предсказание на соответствующей тестовой выборке.\n",
    "# Вычисление ошибки предсказания в виде среднеквадратичной ошибки для каждого разбиения.\n",
    "# Сохранение всех ошибок в список scores.\n",
    "# Вывод среднеквадратичного корня ошибок как итогового результата работы модели.\n",
    "# Таким образом, это реализация кросс-валидации для оценки качества модели регрессии на наборе данных о диабете. Кросс-валидация позволяет более объективно оценить способность модели обобщаться на незнакомых данных.\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(objective=\"reg:linear\")\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    scores.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "display_scores(np.sqrt(scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:54.409408838Z",
     "start_time": "2023-11-15T16:32:53.902346976Z"
    }
   },
   "id": "f8a485363ce89877"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [22:32:54] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [55.68547317 58.18498778 68.622534   64.15281814 68.4826639 ]\n",
      "Mean: 63.026\n",
      "Std: 5.286\n"
     ]
    }
   ],
   "source": [
    "# В этом коде происходит следующее:\n",
    "# \n",
    "# Создание модели XGBRegressor с линейной регрессией в качестве целевой функции.\n",
    "# Применение кросс-валидации с помощью функции cross_val_score.\n",
    "# Параметры:\n",
    "# \n",
    "# Модель: xgb_model\n",
    "# Данные: X и y\n",
    "# Оценка качества: среднеквадратичная ошибка со знаком минус (neg_mean_squared_error)\n",
    "# Количество разбиений: 5\n",
    "# Функция cross_val_score возвращает массив из 5 значений ошибки для каждого разбиения.\n",
    "# Преобразование ошибок в RMSE вычислением корня и сменой знака (поскольку изначально ошибки со знаком минус).\n",
    "# Вывод полученных RMSE с помощью функции display_scores.\n",
    "# Таким образом, этот код позволяет быстро реализовать кросс-валидацию с оценкой по RMSE для модели XGBRegressor, не писать явные циклы.\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "scores = cross_val_score(xgb_model, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "display_scores(np.sqrt(-scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:55.012711220Z",
     "start_time": "2023-11-15T16:32:54.401902362Z"
    }
   },
   "id": "37f25b9b4458250d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.96286\n",
      "[1]\tvalidation_0-auc:0.97742\n",
      "[2]\tvalidation_0-auc:0.97514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dastan/Code/BigData/venv/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tvalidation_0-auc:0.98096\n",
      "[4]\tvalidation_0-auc:0.98637\n",
      "[5]\tvalidation_0-auc:0.99043\n",
      "[6]\tvalidation_0-auc:0.98918\n",
      "[7]\tvalidation_0-auc:0.98980\n",
      "[8]\tvalidation_0-auc:0.98939\n",
      "[9]\tvalidation_0-auc:0.99251\n",
      "[10]\tvalidation_0-auc:0.99209\n",
      "[11]\tvalidation_0-auc:0.99168\n",
      "[12]\tvalidation_0-auc:0.99313\n",
      "[13]\tvalidation_0-auc:0.99313\n",
      "[14]\tvalidation_0-auc:0.99355\n",
      "[15]\tvalidation_0-auc:0.99313\n",
      "[16]\tvalidation_0-auc:0.99272\n",
      "[17]\tvalidation_0-auc:0.99272\n",
      "[18]\tvalidation_0-auc:0.99293\n",
      "[19]\tvalidation_0-auc:0.99293\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.965034965034965"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом коде происходит следующее:\n",
    "# \n",
    "# Загружаются данные о диабете.\n",
    "# Создается модель XGBRegressor без указания гиперпараметров.\n",
    "# Определяются возможные значения гиперпараметров для поиска в виде словаря params. Для каждого параметра задается распределение случайных чисел (функции uniform и randint).\n",
    "# Создается объект RandomizedSearchCV для случайного перебора комбинаций гиперпараметров. Указываются:\n",
    "# модель xgb_model\n",
    "# пространство поиска params\n",
    "# количество итераций\n",
    "# кросс-валидация с 3 разбиениями\n",
    "# вывод прогресса поиска\n",
    "# количество параллельных задач\n",
    "# сохранение значений метрики для обучающей выборки\n",
    "# Вызывается метод поиска fit.\n",
    "# Из полученных результатов cv_results выводятся лучшие найденные комбинации гиперпараметров и значения метрики качества с помощью функции report_best_scores.\n",
    "# Таким образом, этот код реализует случайный поиск гиперпараметров для модели XGBRegressor с оценкой качества по кросс-валидации.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# if more than one evaluation metric are given the last one is used for early stopping\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:55.422404499Z",
     "start_time": "2023-11-15T16:32:55.008761685Z"
    }
   },
   "id": "c767379aac67f513"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший скор: 0.9935497295047857, Лучшая итерация: 14\n"
     ]
    }
   ],
   "source": [
    "# Распечатывается лучшее значение метрики качества (best_score) и номер итерации, на котором оно было достигнуто (best_iteration), из обученной модели xgb_model.\n",
    "# Эти параметры сохраняются в модели после обучения и позволяют посмотреть результаты валидации/кросс-валидации.\n",
    "# \n",
    "# Таким образом, в коде вычисляется метрика качества на тесте и выводятся метрики по итогам обучения модели.\n",
    "print(\"Лучший скор: {0}, Лучшая итерация: {1}\".format(xgb_model.best_score, xgb_model.best_iteration))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:55.422717211Z",
     "start_time": "2023-11-15T16:32:55.417005863Z"
    }
   },
   "id": "1f649049c0ac57d5"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.96286\tvalidation_0-error:0.06993\tvalidation_0-error@0.6:0.06294\n",
      "[1]\tvalidation_0-auc:0.97742\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[2]\tvalidation_0-auc:0.97514\tvalidation_0-error:0.04196\tvalidation_0-error@0.6:0.04196\n",
      "[3]\tvalidation_0-auc:0.98096\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[4]\tvalidation_0-auc:0.98637\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[5]\tvalidation_0-auc:0.99043\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[6]\tvalidation_0-auc:0.98918\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[7]\tvalidation_0-auc:0.98980\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[8]\tvalidation_0-auc:0.98939\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[9]\tvalidation_0-auc:0.99251\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.03497\n",
      "[10]\tvalidation_0-auc:0.99209\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[11]\tvalidation_0-auc:0.99168\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[12]\tvalidation_0-auc:0.99313\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[13]\tvalidation_0-auc:0.99313\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[14]\tvalidation_0-auc:0.99355\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[15]\tvalidation_0-auc:0.99313\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[16]\tvalidation_0-auc:0.99272\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[17]\tvalidation_0-auc:0.99272\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[18]\tvalidation_0-auc:0.99293\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n",
      "[19]\tvalidation_0-auc:0.99293\tvalidation_0-error:0.03497\tvalidation_0-error@0.6:0.04196\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# В этом коде происходит следующее:\n",
    "# \n",
    "# Загружаются данные о раке молочной железы.\n",
    "# Данные разбиваются на обучающую и тестовую выборки с помощью train_test_split.\n",
    "# Создается модель XGBClassifier для бинарной классификации, указываются параметры:\n",
    "# objective - логистическая регрессия\n",
    "# n_estimators - количество деревьев в ансамбле\n",
    "# eval_metric - метрики качества для оценки на валидации: AUC, ошибка классификации и ошибка при пороге 0.6\n",
    "# Модель обучается на обучающей выборке, при этом качество оценивается на тестовой выборке eval_set.\n",
    "# Делаются предсказания модели на тестовых данных.\n",
    "# Таким образом, в коде реализуется разбиение данных, обучение модели с оценкой качества на отложенной выборке и последующие предсказания на тесте.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=20, random_state=42, eval_metric=[\"auc\", \"error\", \"error@0.6\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:55.749935057Z",
     "start_time": "2023-11-15T16:32:55.417184984Z"
    }
   },
   "id": "6dbc6336279b0841"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>В ходе работы я последовательно решал задачи регрессии и классификации с использованием библиотеки xgboost.\n",
    "\n",
    "Для регрессии были использованы данные о диабете. Модель XGBRegressor обучалась предсказывать уровень глюкозы. Была реализована кросс-валидация для оценки качества модели по метрике RMSE. Также проводился случайный перебор гиперпараметров для поиска наилучшей конфигурации модели. Это позволило найти оптимальные настройки и получить адекватную оценку качества модели.\n",
    "\n",
    "Для классификации использовались данные о раке молочной железы и классификации вин. Были обучены модели XGBClassifier и оценено качество с помощью матрицы ошибок и метрики AUC. Также применялось разделение данных на обучение и тест для более объективной оценки модели.\n",
    "\n",
    "Применение xgboost позволило эффективно решить задачи машинного обучения за счет использования градиентного бустинга. Данный подход хорошо себя зарекомендовал для работы с табличными данными. Полученные модели обладают хорошим качеством и могут быть применены на практике. </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec707f50fb98c2e9"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:32:55.750978011Z",
     "start_time": "2023-11-15T16:32:55.749215709Z"
    }
   },
   "id": "ad5abe8f4220f296"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
